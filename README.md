# **基于GAN的垃圾文本检测**

## **核心思想**：

为了解决中文文本的垃圾文本检测问题（这里的垃圾文本的定义主要是同音或同形字词替换，以绕过敏感词审查的文本），基于已有的训练pipeline改进，引入GAN网络（如果用某种办法能得到更多训练样本的话性能自然应该提升，而事实上这个任务是一个二分类，我们需要得到的其实就是更多的负样本，那很自然想到可以使用GAN），分别训练生成器和判别器两个模型，利用生成器自动生成逼真的对抗性垃圾文本（如变形词、同音字替换）扩充训练数据，通过判别器区分真实样本与生成样本，提升模型鲁棒性。

## 训练pipeline：

已有的训练pipeline：这是原论文Adversarial Spam Detector With Character Similarity Network的pipeline，也是课上讲的实战的内容，这里的字符相似性网络从字形、字音两个角度分别判断相似度，然后通过word2vec和自注意力层得到embedding，最后做分类

![image-20250519225612077](README.assets/image-20250519225612077.png)

**基于GAN的训练pipeline：**一般的GAN的生成器的目标应该是去生成以假乱真的样本，然后判别器去判别假样本和真样本。这里有所不同，生成器用正常样本分别去生成更多负样本（垃圾样本），其目标是让判别器分辨不出正样本和负样本，不管这个负样本是生成的还是真实数据；而判别器的目标是区分正负样本。事实上，已有的pipeline可以完全直接作为判别器的pipeline。

另外原有的pipeline有一些细节可以优化，比如相似度阈值可以设为动态的

## 具体实现细节：

1. **生成器**：

### **构建一个可训练的生成器模型** ，其目标是：

> 1. **生成具有“正常语义”的伪垃圾文本** （通过同音词替换）
> 2. **最大程度骗过判别器模型（即垃圾文本识别器）**
> 3. 同时尽可能**保持与原始文本的语义/形式相似度**

| 方案                                            | 描述                                                                 | 优点                                 | 难点                     |
| ----------------------------------------------- | -------------------------------------------------------------------- | ------------------------------------ | ------------------------ |
| **1. REINFORCE 式 TextGAN** (校友的项目)  | 用策略梯度训练生成器                                                 | GAN思想保留、目标明确                | 不稳定，训练难收敛       |
| **2. Gumbel-Softmax + 同音替换生成器**    | 用可微近似离散替换进行训练                                           | 端到端可微，兼容同音词表             | 实现复杂，替换需嵌入网络 |
| **3. Encoder-Decoder + 控制替换 Mask**    | 用 Transformer 在 Mask 位置控制替换                                  | 可控性强，可训练                     | 需标注哪些词能换         |
| **4. 检测器-guided 替换优化器（最推荐）** | 用规则生成初始样本 → 训练一个替换策略（生成器）以最大化判别器误判率 | 易于实现、可迭代优化、符合你现有资源 | 需精细控制生成器目标函数 |

### 目标：

* **G（生成器）** ：学习一个替换策略 $\pi_\theta(w_i \rightarrow \hat{w}_i)$，在给定原始句子和替换词表的前提下，生成一个**伪垃圾文本** $\hat{x}$；
* **D（判别器）** ：已有的垃圾文本检测模型（可冻结或同步训练）；
* **Loss 目标** ：

$$
\mathcal{L}_G = \alpha \cdot \underbrace{\text{CE}(D(\hat{x}), \text{normal})}_{\text{欺骗判别器}} + \beta \cdot \underbrace{1 - \text{Sim}(\hat{x}, x)}_{\text{与原文相似度惩罚}}
$$

---

### 训练流程（GAN-style）：

1. **输入** ：原始正常句子 x，同音词表；
2. **生成器 G** ：对部分词位替换成同音词，输出扰动文本 $\hat{x}$；
3. **判别器 D** ：对 $\hat{x}$ 判断是否是垃圾；
4. **优化 G** ：

* 如果 D 认为它是正常的 → G 成功；
* 若 D 识别出是垃圾 → G 尝试修改替换策略；

反向传播 G 的 loss，最大化其“欺骗成功率 + 句子相似性”。

### 实现：

* G 可以是一个  **Mask-then-predict 模型** （如 BERT-style），在词位上决策“是否替换 + 替换哪一个候选”；
* 替换操作用 **Gumbel-Softmax** 或 **REINFORCE** 做；
* 判别器 D 可以是你现有的垃圾检测模型（BERT/GRU + 分类器）；
* 使用 REINFORCE 优化 G，reward 为：

$$
r = \lambda \cdot (1 - D(\hat)) + (1 - \text(x, \hat))
$$


2. **判别器设计**：

   ### 判别器设计核心思想

判别器承担着双重任务：
1. 准确区分正常文本与垃圾文本（二分类任务）
2. 识别生成器产生的"伪装"垃圾文本

为了提高模型的鲁棒性和检测能力，设计了一个结合已有pipeline的增强型判别器架构。

### 判别器架构详解

判别器将在原有的字符相似性网络基础上进行扩展，主要包含以下组件：

1. **字符相似性特征提取层**
   - 保留原有pipeline中的字形相似度和字音相似度网络
   - 对每个字符进行相似性分析，捕获同音字和形近字替换特征

2. **Word2Vec与自注意力层**
   - 利用Word2Vec捕获词汇语义信息
   - 自注意力机制关注上下文关系，理解替换词在句子中的不协调性

3. **特征融合与增强模块**
   - 融合字符级特征和语义级特征
   - 引入残差连接，保留原始信息流
   - 设计特征增强层，突出关键检测点

4. **对抗判别与分类分支**
   - **正常/垃圾分类任务**：保持原有的二分类功能
   - **真实/生成判别任务**：新增分支，区分真实垃圾文本与生成器产生的文本





### 判别器损失函数设计

判别器的总损失由两部分组成：

$$
L_D = \lambda_1 \cdot L_{classification} + \lambda_2 \cdot L_{adversarial}
$$

其中:
- $L_{classification} = \text{CrossEntropy}(y_{pred}, y_{true})$  # 正常/垃圾文本分类损失
- $L_{adversarial} = \text{BCE}(d_{pred}, d_{true})$  # 真实/生成文本判别损失
- $\lambda_1$, $\lambda_2$ 为平衡两种任务的权重参数



### 判别器训练策略

- **多阶段训练**：
  1. 首先在真实数据上预训练判别器，学习基本的垃圾文本特征
  2. 引入生成器产生的样本，开始对抗训练
  3. 交替训练生成器和判别器，维持平衡

- **差异化采样**：
  - 构建平衡的训练批次：真实正常文本、真实垃圾文本、生成的伪垃圾文本
  - 动态调整各类样本比例，防止判别器过度偏向某一类

- **梯度惩罚机制**：
  - 引入Wasserstein距离与梯度惩罚，提高GAN训练稳定性
  - 减少模式崩溃风险
  - 
3. **对抗训练流程**：

   - 生成器生成对抗样本 → 判别器同时学习分类和对抗检测 → 反馈梯度优化生成器生成更难辨别的样本。

**优势**：

- 自动生成多样化的对抗样本。
- 提升模型对新型变形词、同音替换的检测能力，提高鲁棒性。

## 更多的优化想法：

对判别器做对比学习，进一步通过对比学习优化embedding，使同类样本（垃圾或正常文本）的特征更紧密，不同类样本的特征更分散。
